{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_semantic_change: {\"['dep']\", \"['constit']\", \"['ner']\", \"['None']\", \"['pos']\"}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>['None']</th>\n",
       "      <th>['constit']</th>\n",
       "      <th>['dep']</th>\n",
       "      <th>['ner']</th>\n",
       "      <th>['pos']</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['None']</th>\n",
       "      <td>0</td>\n",
       "      <td>5.084%‡</td>\n",
       "      <td>6.290%‡</td>\n",
       "      <td>25.139%‡</td>\n",
       "      <td>1.606%‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['constit']</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.148%†</td>\n",
       "      <td>19.085%‡</td>\n",
       "      <td>-3.424%‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['dep']</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.733%‡</td>\n",
       "      <td>-4.610%‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['ner']</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.161%‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['pos']</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from scipy import stats\n",
    "\n",
    "all_files = glob.glob(os.path.join('/home/iamlxb3/temp_rsync_dir/story_turing_test/result', '*.csv'))\n",
    "all_df = pd.concat([pd.read_csv(x) for x in all_files])\n",
    "is_change_apply_to_test = True\n",
    "# print(all_df['is_change_apply_to_test'])\n",
    "\n",
    "dataset_name = 'en_writing_prompt' # cn_novel_5billion, en_writing_prompt, en_grover\n",
    "is_pretrain = True\n",
    "language = dataset_name.split('_')[0]\n",
    "\n",
    "if is_pretrain:\n",
    "    classifier_name = f'{language}_roberta'\n",
    "else:\n",
    "    classifier_name = f'{language}_roberta_no_pretrain'\n",
    "\n",
    "all_df = all_df[all_df['is_change_apply_to_test'] == is_change_apply_to_test]\n",
    "all_df = all_df[all_df['char_freq_range'] == 0]\n",
    "all_df = all_df[all_df['dataset_name'] == dataset_name]\n",
    "all_df = all_df[all_df['classifier_name'] == classifier_name]\n",
    "all_df = all_df[~all_df['semantic_change'].isin({'rm_chars_in_freq', 'rm_chars_out_freq'})]\n",
    " \n",
    "\n",
    "# \"['reorder_freq_low2high']\", \"['reorder_freq_high2low']\", \"['reorder_shuffle', 'char_deduplicate']\", \"['not_use_stopword']\", \"['char_deduplicate']\", \"['constit']\", \"['dep']\", \"['reorder_shuffle']\", \"['ner']\", \"['None']\", \"['use_stopword']\", \"['likelihood_rank']\", \"['pos']\"\n",
    "# target_semantic_changes = {\"['None']\",\n",
    "#                            \"['char_deduplicate']\",\n",
    "#                            \"['reorder_shuffle']\",\n",
    "#                            \"['reorder_shuffle', 'char_deduplicate']\", \n",
    "#                            \"['use_stopword']\",\n",
    "#                            \"['not_use_stopword']\"}\n",
    "\n",
    "target_semantic_changes = {\"['None']\",\n",
    "                           \"['constit']\",\n",
    "                           \"['ner']\",\n",
    "                           \"['likelihood_rank']\", \n",
    "                           \"['pos']\",\n",
    "                           \"['dep']\"}\n",
    "\n",
    "all_df = all_df[all_df['semantic_change'].isin(target_semantic_changes)]\n",
    "all_semantic_change = set(all_df['semantic_change'].values)\n",
    "print(f\"all_semantic_change: {all_semantic_change}\")\n",
    "\n",
    "# print(all_df)\n",
    "\n",
    "table_relative_acc = np.zeros((len(all_semantic_change), len(all_semantic_change)), dtype=np.object)\n",
    "table_p_value = np.zeros((len(all_semantic_change), len(all_semantic_change)), dtype=np.object)\n",
    "\n",
    "row_semantic_changes = []\n",
    "col_semantic_changes = []\n",
    "\n",
    "for i, (semantic_change1, semantic_change_df1) in enumerate(all_df.groupby('semantic_change')):\n",
    "    row_semantic_changes.append(semantic_change1)\n",
    "    for j, (semantic_change2, semantic_change_df2) in enumerate(all_df.groupby('semantic_change')):\n",
    "            if semantic_change1 == semantic_change2:\n",
    "                continue\n",
    "            else:\n",
    "                if table_relative_acc[j, i] != 0:\n",
    "                    continue\n",
    "                \n",
    "                test_acc1 = semantic_change_df1['test_acc'].values\n",
    "                test_acc2 = semantic_change_df2['test_acc'].values\n",
    "                \n",
    "                t, p_value = stats.ttest_rel(test_acc1, test_acc2)\n",
    "                \n",
    "                avg_acc1 = np.average(test_acc1)\n",
    "                avg_acc2 = np.average(test_acc2)\n",
    "                \n",
    "                if avg_acc1 - avg_acc2 > 0:\n",
    "                    denominator = avg_acc2\n",
    "                else:\n",
    "                    denominator = avg_acc1\n",
    "                avg_acc_gap = (avg_acc1 - avg_acc2) / denominator\n",
    "                \n",
    "                # cell_value = f'{avg_acc1:.3f}/{avg_acc2:.3f}/{avg_acc_gap*100:.3f}%'\n",
    "                cell_value = f'{avg_acc_gap*100:.3f}%'\n",
    "\n",
    "                if p_value < 0.001:\n",
    "                    cell_value += '‡'\n",
    "                elif p_value < 0.05:\n",
    "                    cell_value += '†'\n",
    "                else:\n",
    "                    pass\n",
    "                table_relative_acc[i, j] = cell_value\n",
    "\n",
    "df = pd.DataFrame(table_relative_acc)\n",
    "df.columns = row_semantic_changes\n",
    "df.index = row_semantic_changes\n",
    "# print(df)\n",
    "display(HTML(df.to_html()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain_df: (180, 17)\n",
      "no_pretrain_df: (120, 17)\n",
      "-------------------------------PRETRAIN RESULT-------------------------------\n",
      "['None'], avg: 0.997±0.002   |   [0.9983230855226384, 0.9938513135830072, 0.9983230855226384, 0.9972051425377306, 0.9960871995528228, 0.9972051425377306, 0.9983230855226384, 0.9944102850754613, 0.9972051425377306, 0.9988820570150924, 0.9988820570150924, 0.999441028507546, 0.9988820570150924, 0.9960871995528228, 0.9983230855226384]\n",
      "['char_deduplicate'], avg: 0.995±0.004   |   [0.9938513135830072, 0.9977641140301844, 0.9938513135830072, 0.9927333705980996, 0.9944102850754613, 0.990497484628284, 0.9944102850754613, 0.9966461710452766, 0.9949692565679151, 0.9916154276131918, 0.9988820570150924, 0.9843487982112912, 0.9988820570150924, 0.9977641140301844, 0.9983230855226384]\n",
      "['constit'], avg: 0.949±0.007   |   [0.9435438792621575, 0.9659027389603131, 0.9547233091112354, 0.9485746226942426, 0.9407490217998882, 0.9502515371716044, 0.9435438792621575, 0.9468977082168808, 0.956400223588597, 0.9541643376187814, 0.9536053661263276, 0.9457797652319732, 0.9435438792621575, 0.9407490217998882, 0.9491335941866964]\n",
      "['dep'], avg: 0.938±0.007   |   [0.93236444941308, 0.9306875349357184, 0.9379541643376188, 0.9429849077697038, 0.9407490217998882, 0.9446618222470654, 0.9306875349357184, 0.9401900503074344, 0.9491335941866964, 0.9446618222470654, 0.9290106204583566, 0.9284516489659028, 0.9441028507546116, 0.9496925656791504, 0.9306875349357184]\n",
      "['ner'], avg: 0.797±0.011   |   [0.7775293460033539, 0.7987702627166015, 0.7859139183901621, 0.8065958636109558, 0.7875908328675237, 0.7959754052543321, 0.8093907210732253, 0.8060368921185019, 0.7808831749580771, 0.8082727780883175, 0.7926215762996087, 0.8144214645053103, 0.7970933482392398, 0.7875908328675237, 0.8071548351034097]\n",
      "['not_use_stopword'], avg: 0.994±0.003   |   [0.9944102850754613, 0.9932923420905534, 0.9977641140301844, 0.9932923420905534, 0.9966461710452766, 0.9882615986584684, 0.9955282280603688, 0.9932923420905534, 0.98993851313583, 0.9893795416433762, 0.9916154276131918, 0.9977641140301844, 0.9988820570150924, 0.9921743991056456, 0.9988820570150924]\n",
      "['pos'], avg: 0.982±0.004   |   [0.9787590832867524, 0.9804359977641139, 0.9871436556735608, 0.9765231973169368, 0.980994969256568, 0.9837898267188372, 0.980994969256568, 0.9776411403018446, 0.9832308552263834, 0.9849077697037452, 0.9742873113471212, 0.9826718837339296, 0.9804359977641139, 0.9916154276131918, 0.9815539407490218]\n",
      "['reorder_freq_high2low'], avg: 0.997±0.001   |   [0.9938513135830072, 0.9983230855226384, 0.9977641140301844, 0.9960871995528228, 0.9977641140301844, 0.9983230855226384, 0.9972051425377306, 0.9972051425377306, 0.9949692565679151, 0.9977641140301844, 0.999441028507546, 0.9966461710452766, 0.9960871995528228, 0.9988820570150924, 0.9960871995528228]\n",
      "['reorder_freq_low2high'], avg: 0.996±0.002   |   [0.9988820570150924, 0.9972051425377306, 0.9944102850754613, 0.9972051425377306, 0.9932923420905534, 0.9972051425377306, 0.9944102850754613, 0.9960871995528228, 0.9938513135830072, 0.9966461710452766, 0.9983230855226384, 0.9966461710452766, 0.9972051425377306, 0.9983230855226384, 0.9960871995528228]\n",
      "['reorder_shuffle', 'char_deduplicate'], avg: 0.992±0.005   |   [0.990497484628284, 0.9966461710452766, 0.98993851313583, 0.9932923420905534, 0.98993851313583, 0.9765231973169368, 0.991056456120738, 0.9865846841811068, 0.9932923420905534, 0.9938513135830072, 0.9944102850754613, 0.991056456120738, 0.9972051425377306, 0.9966461710452766, 0.9955282280603688]\n",
      "['reorder_shuffle'], avg: 0.995±0.002   |   [0.9944102850754613, 0.9960871995528228, 0.9960871995528228, 0.9927333705980996, 0.9966461710452766, 0.9977641140301844, 0.9938513135830072, 0.9944102850754613, 0.9916154276131918, 0.9960871995528228, 0.9972051425377306, 0.9955282280603688, 0.9949692565679151, 0.9960871995528228, 0.9972051425377306]\n",
      "['use_stopword'], avg: 0.986±0.006   |   [0.9932923420905534, 0.9832308552263834, 0.9692565679150364, 0.9871436556735608, 0.9815539407490218, 0.9837898267188372, 0.9921743991056456, 0.985466741196199, 0.9837898267188372, 0.9932923420905534, 0.9888205701509224, 0.9882615986584684, 0.985466741196199, 0.9921743991056456, 0.9815539407490218]\n",
      "-------------------------------NON PRETRAIN RESULT-------------------------------\n",
      "['None'], avg: 0.988±0.004   |   [0.9888205701509224, 0.98993851313583, 0.990497484628284, 0.9888205701509224, 0.9888205701509224, 0.9754052543320292, 0.9888205701509224, 0.985466741196199, 0.9837898267188372, 0.9888205701509224, 0.9877026271660144, 0.991056456120738, 0.98993851313583, 0.9877026271660144, 0.991056456120738]\n",
      "['char_deduplicate'], avg: 0.978±0.011   |   [0.9675796534376748, 0.9893795416433762, 0.9770821688093908, 0.9502515371716044, 0.9893795416433762, 0.9871436556735608, 0.9754052543320292, 0.9686975964225824, 0.9793180547792064, 0.9955282280603688, 0.9686975964225824, 0.9782001117942984, 0.9737283398546674, 0.9877026271660144, 0.9793180547792064]\n",
      "['not_use_stopword'], avg: 0.947±0.024   |   [0.9692565679150364, 0.9474566797093348, 0.9278926774734488, 0.9496925656791504, 0.9362772498602572, 0.941866964784796, 0.9748462828395752, 0.9748462828395752, 0.927333705980995, 0.961430967020682, 0.9737283398546674, 0.9597540525433202, 0.9245388485187256, 0.8859698155394075, 0.9575181665735047]\n",
      "['reorder_freq_high2low'], avg: 0.985±0.005   |   [0.9770821688093908, 0.9832308552263834, 0.9759642258244828, 0.9860257126886528, 0.9837898267188372, 0.9770821688093908, 0.9893795416433762, 0.9826718837339296, 0.9877026271660144, 0.9882615986584684, 0.9865846841811068, 0.9916154276131918, 0.9916154276131918, 0.98993851313583, 0.990497484628284]\n",
      "['reorder_freq_low2high'], avg: 0.987±0.004   |   [0.9865846841811068, 0.9843487982112912, 0.9843487982112912, 0.985466741196199, 0.9849077697037452, 0.9798770262716602, 0.9837898267188372, 0.9832308552263834, 0.9860257126886528, 0.9916154276131918, 0.9888205701509224, 0.9960871995528228, 0.9938513135830072, 0.9860257126886528, 0.990497484628284]\n",
      "['reorder_shuffle', 'char_deduplicate'], avg: 0.975±0.008   |   [0.9860257126886528, 0.9804359977641139, 0.9575181665735047, 0.9765231973169368, 0.9754052543320292, 0.9798770262716602, 0.961989938513136, 0.9793180547792064, 0.9726103968697596, 0.9871436556735608, 0.9664617104527669, 0.9793180547792064, 0.9776411403018446, 0.9631078814980436, 0.9770821688093908]\n",
      "['reorder_shuffle'], avg: 0.986±0.005   |   [0.9882615986584684, 0.980994969256568, 0.9832308552263834, 0.9826718837339296, 0.9860257126886528, 0.9765231973169368, 0.991056456120738, 0.9832308552263834, 0.9849077697037452, 0.980994969256568, 0.9871436556735608, 0.990497484628284, 0.9916154276131918, 0.9927333705980996, 0.9826718837339296]\n",
      "['use_stopword'], avg: 0.894±0.027   |   [0.8949133594186697, 0.9200670765790944, 0.9100055897149244, 0.94242593627725, 0.8345444382336501, 0.8703186137506987, 0.8725544997205142, 0.868641699273337, 0.8725544997205142, 0.8792621576299608, 0.9049748462828396, 0.921743991056456, 0.8954723309111235, 0.9010620458356624, 0.9206260480715484]\n"
     ]
    }
   ],
   "source": [
    "# pre-train vs non pre-train\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pdb\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "all_files = glob.glob(os.path.join('/home/iamlxb3/temp_rsync_dir/story_turing_test/result', '*.csv'))\n",
    "all_df = pd.concat([pd.read_csv(x) for x in all_files])\n",
    "is_change_apply_to_test = True\n",
    "\n",
    "dataset_name = 'en_writing_prompt' # cn_novel_5billion, en_writing_prompt, en_grover\n",
    "language = dataset_name.split('_')[0]\n",
    "\n",
    "all_df = all_df[all_df['dataset_name'] == dataset_name]\n",
    "all_df = all_df[(all_df['is_change_apply_to_test'] == is_change_apply_to_test) & (all_df['char_freq_range'] == 0)]\n",
    "pretrain_df = all_df[all_df['classifier_name']==f'{language}_roberta'] # filter non-pretrain models\n",
    "no_pretrain_df = all_df[all_df['classifier_name']==f'{language}_roberta_no_pretrain'] # filter non-pretrain models\n",
    "\n",
    "pretrain_result = collections.defaultdict(lambda: [])\n",
    "for semantic_change, tmp_df in pretrain_df.groupby('semantic_change'):\n",
    "    pretrain_result[semantic_change].extend(tmp_df['test_acc'].values)\n",
    "\n",
    "no_pretrain_result = collections.defaultdict(lambda: [])\n",
    "for semantic_change, tmp_df in no_pretrain_df.groupby('semantic_change'):\n",
    "    no_pretrain_result[semantic_change].extend(tmp_df['test_acc'].values)\n",
    "    \n",
    "print(f\"pretrain_df: {pretrain_df.shape}\")\n",
    "print(f\"no_pretrain_df: {no_pretrain_df.shape}\")\n",
    "\n",
    "print(\"-------------------------------PRETRAIN RESULT-------------------------------\")\n",
    "for k,v in pretrain_result.items():\n",
    "    print(f\"{k}, avg: {np.average(v):.3f}±{np.std(v):.3f}   |   {v}\")\n",
    "# print(dict(pretrain_result))\n",
    "\n",
    "print(\"-------------------------------NON PRETRAIN RESULT-------------------------------\")\n",
    "for k,v in no_pretrain_result.items():\n",
    "    print(f\"{k}, avg: {np.average(v):.3f}±{np.std(v):.3f}   |   {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply_totest_df: (105, 13)\n",
      "no_apply_totest_df: (75, 13)\n",
      "-------------------------------APPLY TO TEST RESULT-------------------------------\n",
      "['None'], avg: 0.955±0.010   |   [0.9655784244144784, 0.9488999290276792, 0.93541518807665, 0.9446415897799858, 0.9506742370475516, 0.9517388218594748, 0.949609652235628, 0.9698367636621718, 0.9588360539389638, 0.9616749467707594, 0.9680624556422996, 0.9623846699787084, 0.9630943931866572, 0.9460610361958836, 0.9467707594038324]\n",
      "['char_deduplicate'], avg: 0.934±0.010   |   [0.9336408800567778, 0.936834634492548, 0.9357700496806246, 0.9457061745919092, 0.9268985095812632, 0.9073811213626686, 0.9389638041163946, 0.9350603264726756, 0.9375443577004968, 0.9464158977998579, 0.9304471256210078, 0.9297374024130588, 0.9215755855216464, 0.9421575585521648, 0.939318665720369]\n",
      "['likelihood_rank'], avg: 0.769±0.009   |   [0.769694819020582, 0.7579843860894251, 0.765791341376863, 0.7700496806245565, 0.7618878637331441, 0.7615330021291696, 0.7572746628814763, 0.7906316536550745, 0.758694109297374, 0.7814052519517388, 0.769694819020582, 0.7732434350603264, 0.7739531582682754, 0.7789212207239177, 0.758694109297374]\n",
      "['reorder_freq_high2low'], avg: 0.929±0.006   |   [0.9329311568488291, 0.9268985095812632, 0.9254790631653655, 0.9329311568488291, 0.936834634492548, 0.921220723917672, 0.9396735273243436, 0.9293825408090844, 0.9251242015613912, 0.9233498935415188, 0.9375443577004968, 0.9272533711852378, 0.9233498935415188, 0.9347054648687012, 0.918026969481902]\n",
      "['reorder_freq_low2high'], avg: 0.929±0.005   |   [0.9318665720369056, 0.9247693399574166, 0.9329311568488291, 0.9329311568488291, 0.9332860184528036, 0.9254790631653655, 0.9343506032647269, 0.92264017033357, 0.9276082327892122, 0.9272533711852378, 0.9350603264726756, 0.9251242015613912, 0.9208658623136976, 0.9325762952448544, 0.9222853087295956]\n",
      "['reorder_shuffle', 'char_deduplicate'], avg: 0.906±0.004   |   [0.9095102909865151, 0.9048970901348474, 0.9077359829666429, 0.9141234918381832, 0.9059616749467708, 0.9080908445706176, 0.911639460610362, 0.897444996451384, 0.9020581973030518, 0.9027679205110009, 0.9048970901348474, 0.9077359829666429, 0.905251951738822, 0.908445706174592, 0.9002838892831796]\n",
      "['reorder_shuffle'], avg: 0.931±0.005   |   [0.9364797728885734, 0.9247693399574166, 0.9297374024130588, 0.9332860184528036, 0.9329311568488291, 0.92264017033357, 0.9403832505322924, 0.9339957416607524, 0.9297374024130588, 0.9276082327892122, 0.9378992193044712, 0.9325762952448544, 0.9261887863733144, 0.9350603264726756, 0.92583392476934]\n",
      "-------------------------------NON APPLY TO TEST RESULT-------------------------------\n",
      "['char_deduplicate'], avg: 0.499±0.008   |   [0.49680624556423003, 0.48580553584102204, 0.4950319375443577, 0.4939673527324344, 0.4879347054648687, 0.5010645848119234, 0.5088715400993612, 0.5035486160397445, 0.5003548616039745, 0.4943222143364088, 0.5099361249112846, 0.4989354151880767, 0.4943222143364088, 0.5056777856635912, 0.514194464158978]\n",
      "['reorder_freq_high2low'], avg: 0.500±0.008   |   [0.4971611071682044, 0.4861603974449965, 0.4950319375443577, 0.4953867991483322, 0.4882895670688431, 0.5014194464158978, 0.5106458481192335, 0.5035486160397445, 0.5014194464158978, 0.4943222143364088, 0.5106458481192335, 0.4989354151880767, 0.4953867991483322, 0.507097232079489, 0.514194464158978]\n",
      "['reorder_freq_low2high'], avg: 0.500±0.008   |   [0.49680624556423003, 0.4861603974449965, 0.4950319375443577, 0.4939673527324344, 0.4879347054648687, 0.5010645848119234, 0.5095812633073101, 0.5035486160397445, 0.5014194464158978, 0.4943222143364088, 0.5099361249112846, 0.4989354151880767, 0.4943222143364088, 0.5056777856635912, 0.514194464158978]\n",
      "['reorder_shuffle', 'char_deduplicate'], avg: 0.499±0.008   |   [0.49680624556423003, 0.48580553584102204, 0.4950319375443577, 0.4939673527324344, 0.4879347054648687, 0.5010645848119234, 0.5088715400993612, 0.5035486160397445, 0.5003548616039745, 0.4943222143364088, 0.5099361249112846, 0.4989354151880767, 0.4943222143364088, 0.5056777856635912, 0.514194464158978]\n",
      "['reorder_shuffle'], avg: 0.642±0.034   |   [0.6458481192334989, 0.6501064584811923, 0.6550745209368346, 0.6327182398864443, 0.5901348474095103, 0.7061745919091554, 0.662526614620298, 0.5865862313697658, 0.6433640880056778, 0.5823278921220724, 0.6639460610361959, 0.6391057487579844, 0.6430092264017033, 0.6884315117104329, 0.6479772888573456]\n"
     ]
    }
   ],
   "source": [
    "# apply_to_test vs not apply_to_test\n",
    "\n",
    "# pre-train vs non pre-train\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pdb\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "all_files = glob.glob(os.path.join('../result/', '*.csv'))\n",
    "all_df = pd.concat([pd.read_csv(x) for x in all_files])\n",
    "is_change_apply_to_test = True\n",
    "\n",
    "all_df = all_df[(all_df['classifier_name']=='cn_roberta') & (all_df['char_freq_range'] == 0)]\n",
    "\n",
    "apply_totest_df = all_df[all_df['is_change_apply_to_test']==True] # filter non-pretrain models\n",
    "no_apply_totest_df = all_df[all_df['is_change_apply_to_test']==False] # filter non-pretrain models\n",
    "\n",
    "apply_totest_result = collections.defaultdict(lambda: [])\n",
    "for semantic_change, tmp_df in apply_totest_df.groupby('semantic_change'):\n",
    "    apply_totest_result[semantic_change].extend(tmp_df['test_acc'].values)\n",
    "\n",
    "no_apply_totest_result = collections.defaultdict(lambda: [])\n",
    "for semantic_change, tmp_df in no_apply_totest_df.groupby('semantic_change'):\n",
    "    no_apply_totest_result[semantic_change].extend(tmp_df['test_acc'].values)\n",
    "    \n",
    "print(f\"apply_totest_df: {apply_totest_df.shape}\")\n",
    "print(f\"no_apply_totest_df: {no_apply_totest_df.shape}\")\n",
    "\n",
    "print(\"-------------------------------APPLY TO TEST RESULT-------------------------------\")\n",
    "for k,v in apply_totest_result.items():\n",
    "    print(f\"{k}, avg: {np.average(v):.3f}±{np.std(v):.3f}   |   {v}\")\n",
    "\n",
    "print(\"-------------------------------NON APPLY TO TEST RESULT-------------------------------\")\n",
    "for k,v in no_apply_totest_result.items():\n",
    "    print(f\"{k}, avg: {np.average(v):.3f}±{np.std(v):.3f}   |   {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply_to_test vs not apply_to_test\n",
    "\n",
    "# pre-train & corrupted on train\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pdb\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "all_files = glob.glob(os.path.join('../result/', '*.csv'))\n",
    "all_df = pd.concat([pd.read_csv(x) for x in all_files])\n",
    "is_change_apply_to_test = True\n",
    "\n",
    "all_df = all_df[(all_df['classifier_name']=='cn_roberta') & (all_df['char_freq_range'] == 0)]\n",
    "\n",
    "apply_totest_df = all_df[(all_df['is_change_apply_to_test']==True) & (all_df['is_change_apply_to_train']==False)] # filter non-pretrain models\n",
    "\n",
    "apply_totest_result = collections.defaultdict(lambda: [])\n",
    "for semantic_change, tmp_df in apply_totest_df.groupby('semantic_change'):\n",
    "    apply_totest_result[semantic_change].extend(tmp_df['test_acc'].values)\n",
    "    \n",
    "print(f\"apply_totest_df: {apply_totest_df.shape}\")\n",
    "\n",
    "print(\"-------------------------------APPLY TO TEST RESULT but NOT to Train result-------------------------------\")\n",
    "for k,v in apply_totest_result.items():\n",
    "    print(f\"{k}, avg: {np.average(v):.3f}±{np.std(v):.3f}   |   {v}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
