{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>['None']</th>\n",
       "      <th>['char_deduplicate']</th>\n",
       "      <th>['likelihood_rank']</th>\n",
       "      <th>['reorder_freq_high2low']</th>\n",
       "      <th>['reorder_freq_low2high']</th>\n",
       "      <th>['reorder_shuffle', 'char_deduplicate']</th>\n",
       "      <th>['reorder_shuffle']</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['None']</th>\n",
       "      <td>0</td>\n",
       "      <td>-5.589%‡</td>\n",
       "      <td>17.242%‡</td>\n",
       "      <td>2.804%‡</td>\n",
       "      <td>2.780%‡</td>\n",
       "      <td>-5.502%‡</td>\n",
       "      <td>2.997%‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['char_deduplicate']</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.795%‡</td>\n",
       "      <td>8.550%‡</td>\n",
       "      <td>8.525%‡</td>\n",
       "      <td>0.082%</td>\n",
       "      <td>8.753%‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['likelihood_rank']</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-14.045%‡</td>\n",
       "      <td>-14.071%‡</td>\n",
       "      <td>-23.693%‡</td>\n",
       "      <td>-13.831%‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['reorder_freq_high2low']</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.023%</td>\n",
       "      <td>-8.460%‡</td>\n",
       "      <td>0.187%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['reorder_freq_low2high']</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.436%‡</td>\n",
       "      <td>0.211%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['reorder_shuffle', 'char_deduplicate']</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.664%‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['reorder_shuffle']</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from scipy import stats\n",
    "\n",
    "all_files = glob.glob(os.path.join('../result/', '*.csv'))\n",
    "all_df = pd.concat([pd.read_csv(x) for x in all_files])\n",
    "is_change_apply_to_test = True\n",
    "# print(all_df['is_change_apply_to_test'])\n",
    "\n",
    "all_df = all_df[all_df['is_change_apply_to_test'] == is_change_apply_to_test]\n",
    "all_df = all_df[all_df['char_freq_range'] == 0]\n",
    "all_df = all_df[all_df['classifier_name'] == 'cn_roberta_no_pretrain']\n",
    "all_df = all_df[~all_df['semantic_change'].isin({'rm_chars_in_freq', 'rm_chars_out_freq'})]\n",
    "\n",
    "\n",
    "\n",
    "all_semantic_change = set(all_df['semantic_change'].values)\n",
    "\n",
    "table_relative_acc = np.zeros((len(all_semantic_change), len(all_semantic_change)), dtype=np.object)\n",
    "table_p_value = np.zeros((len(all_semantic_change), len(all_semantic_change)), dtype=np.object)\n",
    "\n",
    "row_semantic_changes = []\n",
    "col_semantic_changes = []\n",
    "\n",
    "for i, (semantic_change1, semantic_change_df1) in enumerate(all_df.groupby('semantic_change')):\n",
    "    row_semantic_changes.append(semantic_change1)\n",
    "    for j, (semantic_change2, semantic_change_df2) in enumerate(all_df.groupby('semantic_change')):\n",
    "            if semantic_change1 == semantic_change2:\n",
    "                continue\n",
    "            else:\n",
    "                if table_relative_acc[j, i] != 0:\n",
    "                    continue\n",
    "                \n",
    "                test_acc1 = semantic_change_df1['test_acc'].values\n",
    "                test_acc2 = semantic_change_df2['test_acc'].values\n",
    "                \n",
    "                t, p_value = stats.ttest_rel(test_acc1, test_acc2)\n",
    "                \n",
    "                avg_acc1 = np.average(test_acc1)\n",
    "                avg_acc2 = np.average(test_acc2)\n",
    "                \n",
    "                if avg_acc1 - avg_acc2 > 0:\n",
    "                    denominator = avg_acc2\n",
    "                else:\n",
    "                    denominator = avg_acc1\n",
    "                avg_acc_gap = (avg_acc1 - avg_acc2) / denominator\n",
    "                \n",
    "                # cell_value = f'{avg_acc1:.3f}/{avg_acc2:.3f}/{avg_acc_gap*100:.3f}%'\n",
    "                cell_value = f'{avg_acc_gap*100:.3f}%'\n",
    "\n",
    "                if p_value < 0.001:\n",
    "                    cell_value += '‡'\n",
    "                elif p_value < 0.05:\n",
    "                    cell_value += '†'\n",
    "                else:\n",
    "                    pass\n",
    "                table_relative_acc[i, j] = cell_value\n",
    "\n",
    "df = pd.DataFrame(table_relative_acc)\n",
    "df.columns = row_semantic_changes\n",
    "df.index = row_semantic_changes\n",
    "# print(df)\n",
    "display(HTML(df.to_html()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain_df: (105, 13)\n",
      "no_pretrain_df: (105, 13)\n",
      "-------------------------------PRETRAIN RESULT-------------------------------\n",
      "['None'], avg: 0.955±0.010   |   [0.9655784244144784, 0.9488999290276792, 0.93541518807665, 0.9446415897799858, 0.9506742370475516, 0.9517388218594748, 0.949609652235628, 0.9698367636621718, 0.9588360539389638, 0.9616749467707594, 0.9680624556422996, 0.9623846699787084, 0.9630943931866572, 0.9460610361958836, 0.9467707594038324]\n",
      "['char_deduplicate'], avg: 0.934±0.010   |   [0.9336408800567778, 0.936834634492548, 0.9357700496806246, 0.9457061745919092, 0.9268985095812632, 0.9073811213626686, 0.9389638041163946, 0.9350603264726756, 0.9375443577004968, 0.9464158977998579, 0.9304471256210078, 0.9297374024130588, 0.9215755855216464, 0.9421575585521648, 0.939318665720369]\n",
      "['likelihood_rank'], avg: 0.769±0.009   |   [0.769694819020582, 0.7579843860894251, 0.765791341376863, 0.7700496806245565, 0.7618878637331441, 0.7615330021291696, 0.7572746628814763, 0.7906316536550745, 0.758694109297374, 0.7814052519517388, 0.769694819020582, 0.7732434350603264, 0.7739531582682754, 0.7789212207239177, 0.758694109297374]\n",
      "['reorder_freq_high2low'], avg: 0.929±0.006   |   [0.9329311568488291, 0.9268985095812632, 0.9254790631653655, 0.9329311568488291, 0.936834634492548, 0.921220723917672, 0.9396735273243436, 0.9293825408090844, 0.9251242015613912, 0.9233498935415188, 0.9375443577004968, 0.9272533711852378, 0.9233498935415188, 0.9347054648687012, 0.918026969481902]\n",
      "['reorder_freq_low2high'], avg: 0.929±0.005   |   [0.9318665720369056, 0.9247693399574166, 0.9329311568488291, 0.9329311568488291, 0.9332860184528036, 0.9254790631653655, 0.9343506032647269, 0.92264017033357, 0.9276082327892122, 0.9272533711852378, 0.9350603264726756, 0.9251242015613912, 0.9208658623136976, 0.9325762952448544, 0.9222853087295956]\n",
      "['reorder_shuffle', 'char_deduplicate'], avg: 0.906±0.004   |   [0.9095102909865151, 0.9048970901348474, 0.9077359829666429, 0.9141234918381832, 0.9059616749467708, 0.9080908445706176, 0.911639460610362, 0.897444996451384, 0.9020581973030518, 0.9027679205110009, 0.9048970901348474, 0.9077359829666429, 0.905251951738822, 0.908445706174592, 0.9002838892831796]\n",
      "['reorder_shuffle'], avg: 0.931±0.005   |   [0.9364797728885734, 0.9247693399574166, 0.9297374024130588, 0.9332860184528036, 0.9329311568488291, 0.92264017033357, 0.9403832505322924, 0.9339957416607524, 0.9297374024130588, 0.9276082327892122, 0.9378992193044712, 0.9325762952448544, 0.9261887863733144, 0.9350603264726756, 0.92583392476934]\n",
      "-------------------------------NON PRETRAIN RESULT-------------------------------\n",
      "['None'], avg: 0.845±0.011   |   [0.8378282469836764, 0.8314407381121363, 0.8591199432221434, 0.8623136976579134, 0.8427963094393187, 0.8573456352022711, 0.8520227111426544, 0.8431511710432931, 0.8271823988644429, 0.8587650816181689, 0.8420865862313698, 0.8509581263307309, 0.8271823988644429, 0.8332150461320085, 0.8474095102909865]\n",
      "['char_deduplicate'], avg: 0.892±0.005   |   [0.8938963804116394, 0.8864442867281759, 0.8889283179559971, 0.8949609652235628, 0.8885734563520227, 0.8946061036195884, 0.8960255500354861, 0.8992193044712562, 0.8850248403122782, 0.8853797019162527, 0.9006387508871541, 0.8960255500354861, 0.8882185947480482, 0.8910574875798438, 0.8921220723917672]\n",
      "['likelihood_rank'], avg: 0.721±0.008   |   [0.7256919801277502, 0.7285308729595458, 0.7260468417317246, 0.71611071682044, 0.7207239176721079, 0.7079488999290277, 0.7207239176721079, 0.7274662881476224, 0.7086586231369766, 0.7242725337118524, 0.7334989354151881, 0.7171753016323634, 0.7104329311568488, 0.7285308729595458, 0.7132718239886444]\n",
      "['reorder_freq_high2low'], avg: 0.822±0.007   |   [0.8147622427253371, 0.8080198722498225, 0.8278921220723917, 0.8264726756564941, 0.8314407381121363, 0.8250532292405962, 0.8300212916962385, 0.8129879347054648, 0.8140525195173882, 0.8325053229240597, 0.8179559971611071, 0.8215046132008517, 0.8200851667849539, 0.8218594748048261, 0.8225691980127751]\n",
      "['reorder_freq_low2high'], avg: 0.822±0.009   |   [0.8215046132008517, 0.8058907026259758, 0.8229240596167494, 0.8278921220723917, 0.8211497515968772, 0.8257629524485451, 0.8303761533002131, 0.8090844570617459, 0.8140525195173882, 0.8427963094393187, 0.8211497515968772, 0.8293115684882896, 0.8158268275372604, 0.8207948899929027, 0.8215046132008517]\n",
      "['reorder_shuffle', 'char_deduplicate'], avg: 0.891±0.005   |   [0.8907026259758695, 0.8878637331440739, 0.8899929027679205, 0.9017033356990772, 0.8882185947480482, 0.8857345635202271, 0.8949609652235628, 0.8970901348474095, 0.8818310858765082, 0.8914123491838183, 0.8995741660752307, 0.8914123491838183, 0.8924769339957417, 0.8892831795599716, 0.8878637331440739]\n",
      "['reorder_shuffle'], avg: 0.820±0.010   |   [0.8200851667849539, 0.7973740241305891, 0.8296664300922639, 0.8293115684882896, 0.8236337828246983, 0.8335699077359829, 0.8353442157558553, 0.8161816891412349, 0.8073101490418737, 0.8328601845280341, 0.8136976579134138, 0.8179559971611071, 0.8144073811213627, 0.8161816891412349, 0.8165365507452094]\n"
     ]
    }
   ],
   "source": [
    "# pre-train vs non pre-train\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pdb\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "all_files = glob.glob(os.path.join('../result/', '*.csv'))\n",
    "all_df = pd.concat([pd.read_csv(x) for x in all_files])\n",
    "is_change_apply_to_test = True\n",
    "\n",
    "all_df = all_df[(all_df['is_change_apply_to_test'] == is_change_apply_to_test) & (all_df['char_freq_range'] == 0)]\n",
    "pretrain_df = all_df[all_df['classifier_name']=='cn_roberta'] # filter non-pretrain models\n",
    "no_pretrain_df = all_df[all_df['classifier_name']=='cn_roberta_no_pretrain'] # filter non-pretrain models\n",
    "\n",
    "pretrain_result = collections.defaultdict(lambda: [])\n",
    "for semantic_change, tmp_df in pretrain_df.groupby('semantic_change'):\n",
    "    pretrain_result[semantic_change].extend(tmp_df['test_acc'].values)\n",
    "\n",
    "no_pretrain_result = collections.defaultdict(lambda: [])\n",
    "for semantic_change, tmp_df in no_pretrain_df.groupby('semantic_change'):\n",
    "    no_pretrain_result[semantic_change].extend(tmp_df['test_acc'].values)\n",
    "    \n",
    "print(f\"pretrain_df: {pretrain_df.shape}\")\n",
    "print(f\"no_pretrain_df: {no_pretrain_df.shape}\")\n",
    "\n",
    "print(\"-------------------------------PRETRAIN RESULT-------------------------------\")\n",
    "for k,v in pretrain_result.items():\n",
    "    print(f\"{k}, avg: {np.average(v):.3f}±{np.std(v):.3f}   |   {v}\")\n",
    "# print(dict(pretrain_result))\n",
    "\n",
    "print(\"-------------------------------NON PRETRAIN RESULT-------------------------------\")\n",
    "for k,v in no_pretrain_result.items():\n",
    "    print(f\"{k}, avg: {np.average(v):.3f}±{np.std(v):.3f}   |   {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply_totest_df: (105, 13)\n",
      "no_apply_totest_df: (75, 13)\n",
      "-------------------------------APPLY TO TEST RESULT-------------------------------\n",
      "['None'], avg: 0.955±0.010   |   [0.9655784244144784, 0.9488999290276792, 0.93541518807665, 0.9446415897799858, 0.9506742370475516, 0.9517388218594748, 0.949609652235628, 0.9698367636621718, 0.9588360539389638, 0.9616749467707594, 0.9680624556422996, 0.9623846699787084, 0.9630943931866572, 0.9460610361958836, 0.9467707594038324]\n",
      "['char_deduplicate'], avg: 0.934±0.010   |   [0.9336408800567778, 0.936834634492548, 0.9357700496806246, 0.9457061745919092, 0.9268985095812632, 0.9073811213626686, 0.9389638041163946, 0.9350603264726756, 0.9375443577004968, 0.9464158977998579, 0.9304471256210078, 0.9297374024130588, 0.9215755855216464, 0.9421575585521648, 0.939318665720369]\n",
      "['likelihood_rank'], avg: 0.769±0.009   |   [0.769694819020582, 0.7579843860894251, 0.765791341376863, 0.7700496806245565, 0.7618878637331441, 0.7615330021291696, 0.7572746628814763, 0.7906316536550745, 0.758694109297374, 0.7814052519517388, 0.769694819020582, 0.7732434350603264, 0.7739531582682754, 0.7789212207239177, 0.758694109297374]\n",
      "['reorder_freq_high2low'], avg: 0.929±0.006   |   [0.9329311568488291, 0.9268985095812632, 0.9254790631653655, 0.9329311568488291, 0.936834634492548, 0.921220723917672, 0.9396735273243436, 0.9293825408090844, 0.9251242015613912, 0.9233498935415188, 0.9375443577004968, 0.9272533711852378, 0.9233498935415188, 0.9347054648687012, 0.918026969481902]\n",
      "['reorder_freq_low2high'], avg: 0.929±0.005   |   [0.9318665720369056, 0.9247693399574166, 0.9329311568488291, 0.9329311568488291, 0.9332860184528036, 0.9254790631653655, 0.9343506032647269, 0.92264017033357, 0.9276082327892122, 0.9272533711852378, 0.9350603264726756, 0.9251242015613912, 0.9208658623136976, 0.9325762952448544, 0.9222853087295956]\n",
      "['reorder_shuffle', 'char_deduplicate'], avg: 0.906±0.004   |   [0.9095102909865151, 0.9048970901348474, 0.9077359829666429, 0.9141234918381832, 0.9059616749467708, 0.9080908445706176, 0.911639460610362, 0.897444996451384, 0.9020581973030518, 0.9027679205110009, 0.9048970901348474, 0.9077359829666429, 0.905251951738822, 0.908445706174592, 0.9002838892831796]\n",
      "['reorder_shuffle'], avg: 0.931±0.005   |   [0.9364797728885734, 0.9247693399574166, 0.9297374024130588, 0.9332860184528036, 0.9329311568488291, 0.92264017033357, 0.9403832505322924, 0.9339957416607524, 0.9297374024130588, 0.9276082327892122, 0.9378992193044712, 0.9325762952448544, 0.9261887863733144, 0.9350603264726756, 0.92583392476934]\n",
      "-------------------------------NON APPLY TO TEST RESULT-------------------------------\n",
      "['char_deduplicate'], avg: 0.499±0.008   |   [0.49680624556423003, 0.48580553584102204, 0.4950319375443577, 0.4939673527324344, 0.4879347054648687, 0.5010645848119234, 0.5088715400993612, 0.5035486160397445, 0.5003548616039745, 0.4943222143364088, 0.5099361249112846, 0.4989354151880767, 0.4943222143364088, 0.5056777856635912, 0.514194464158978]\n",
      "['reorder_freq_high2low'], avg: 0.500±0.008   |   [0.4971611071682044, 0.4861603974449965, 0.4950319375443577, 0.4953867991483322, 0.4882895670688431, 0.5014194464158978, 0.5106458481192335, 0.5035486160397445, 0.5014194464158978, 0.4943222143364088, 0.5106458481192335, 0.4989354151880767, 0.4953867991483322, 0.507097232079489, 0.514194464158978]\n",
      "['reorder_freq_low2high'], avg: 0.500±0.008   |   [0.49680624556423003, 0.4861603974449965, 0.4950319375443577, 0.4939673527324344, 0.4879347054648687, 0.5010645848119234, 0.5095812633073101, 0.5035486160397445, 0.5014194464158978, 0.4943222143364088, 0.5099361249112846, 0.4989354151880767, 0.4943222143364088, 0.5056777856635912, 0.514194464158978]\n",
      "['reorder_shuffle', 'char_deduplicate'], avg: 0.499±0.008   |   [0.49680624556423003, 0.48580553584102204, 0.4950319375443577, 0.4939673527324344, 0.4879347054648687, 0.5010645848119234, 0.5088715400993612, 0.5035486160397445, 0.5003548616039745, 0.4943222143364088, 0.5099361249112846, 0.4989354151880767, 0.4943222143364088, 0.5056777856635912, 0.514194464158978]\n",
      "['reorder_shuffle'], avg: 0.642±0.034   |   [0.6458481192334989, 0.6501064584811923, 0.6550745209368346, 0.6327182398864443, 0.5901348474095103, 0.7061745919091554, 0.662526614620298, 0.5865862313697658, 0.6433640880056778, 0.5823278921220724, 0.6639460610361959, 0.6391057487579844, 0.6430092264017033, 0.6884315117104329, 0.6479772888573456]\n"
     ]
    }
   ],
   "source": [
    "# apply_to_test vs not apply_to_test\n",
    "\n",
    "# pre-train vs non pre-train\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pdb\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "all_files = glob.glob(os.path.join('../result/', '*.csv'))\n",
    "all_df = pd.concat([pd.read_csv(x) for x in all_files])\n",
    "is_change_apply_to_test = True\n",
    "\n",
    "all_df = all_df[(all_df['classifier_name']=='cn_roberta') & (all_df['char_freq_range'] == 0)]\n",
    "\n",
    "apply_totest_df = all_df[all_df['is_change_apply_to_test']==True] # filter non-pretrain models\n",
    "no_apply_totest_df = all_df[all_df['is_change_apply_to_test']==False] # filter non-pretrain models\n",
    "\n",
    "apply_totest_result = collections.defaultdict(lambda: [])\n",
    "for semantic_change, tmp_df in apply_totest_df.groupby('semantic_change'):\n",
    "    apply_totest_result[semantic_change].extend(tmp_df['test_acc'].values)\n",
    "\n",
    "no_apply_totest_result = collections.defaultdict(lambda: [])\n",
    "for semantic_change, tmp_df in no_apply_totest_df.groupby('semantic_change'):\n",
    "    no_apply_totest_result[semantic_change].extend(tmp_df['test_acc'].values)\n",
    "    \n",
    "print(f\"apply_totest_df: {apply_totest_df.shape}\")\n",
    "print(f\"no_apply_totest_df: {no_apply_totest_df.shape}\")\n",
    "\n",
    "print(\"-------------------------------APPLY TO TEST RESULT-------------------------------\")\n",
    "for k,v in apply_totest_result.items():\n",
    "    print(f\"{k}, avg: {np.average(v):.3f}±{np.std(v):.3f}   |   {v}\")\n",
    "\n",
    "print(\"-------------------------------NON APPLY TO TEST RESULT-------------------------------\")\n",
    "for k,v in no_apply_totest_result.items():\n",
    "    print(f\"{k}, avg: {np.average(v):.3f}±{np.std(v):.3f}   |   {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply_to_test vs not apply_to_test\n",
    "\n",
    "# pre-train & corrupted on train\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pdb\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "all_files = glob.glob(os.path.join('../result/', '*.csv'))\n",
    "all_df = pd.concat([pd.read_csv(x) for x in all_files])\n",
    "is_change_apply_to_test = True\n",
    "\n",
    "all_df = all_df[(all_df['classifier_name']=='cn_roberta') & (all_df['char_freq_range'] == 0)]\n",
    "\n",
    "apply_totest_df = all_df[(all_df['is_change_apply_to_test']==True) & (all_df['is_change_apply_to_train']==False)] # filter non-pretrain models\n",
    "\n",
    "apply_totest_result = collections.defaultdict(lambda: [])\n",
    "for semantic_change, tmp_df in apply_totest_df.groupby('semantic_change'):\n",
    "    apply_totest_result[semantic_change].extend(tmp_df['test_acc'].values)\n",
    "    \n",
    "print(f\"apply_totest_df: {apply_totest_df.shape}\")\n",
    "\n",
    "print(\"-------------------------------APPLY TO TEST RESULT but NOT to Train result-------------------------------\")\n",
    "for k,v in apply_totest_result.items():\n",
    "    print(f\"{k}, avg: {np.average(v):.3f}±{np.std(v):.3f}   |   {v}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
